### Methodology Overview
Micro-benchmarking, that is benchmarking operations that normally last milliseconds rather than second, is a notoriously tricky affair. In this section I'd like to elaborate on the potential difficulties of the affair, as well as describe how **Funq** solves them.

#### Non-uniformity

Part of benchmarking involves singling out the particular set of operations you want to test, so that each tests differs in that particular set of operations, but all are identical in every other respect.

When coding similar tests by hand, however, this is very tricky to do. It may be simple in principle, but in practice you may not always know whether two bits of code are meaningfully different from one another. Even when you do know this, you're liable to making small errors that undermine the integrity of the benchmark.

The end result is that your benchmark gives nonsense results, or even worse, gives plausible but fundamentally flawed ones.

**Funq** handles this issue by making all benchmarks uniform. That is, every test uses the exact same human-written bit of code. 
#### Noise
Performance measurements are subject to *noise* of various forms. Here are some example sources of noise:

1. Noise from the testing infrastructure, such as calling a method or instantiating an object that isn't part of what you're trying to benchmark.
2. .NET Framework processes that run in the background, such as the GC and the JIT compiler.
3. External applications.

These factors contaminate your measurements, because they influence the time it takes your benchmark to execute.

**Funq** handles noise using several precautions.

1. Tests are executed in a 'clean' environment. The GC is run before every test, and the tests execute on a dedicated thread.
1. Every test is executed many times. The first several runs are dropped unconditionally (this takes care of noise introduced by the JITter). The results are then filtered for outliers (unexpectedly large/small results), and then averaged.
2. Every test contains many iterations of an operation, or else works with a relatively large dataset.
2. There is very little overhead from the testing infrastructure. Few, if any, constructors or methods are called that aren't part of the test itself. When methods are called, they're not virtual.

#### Faith of reproduction
The code you write in a high-level language such as C# doesn't necessarily correspond to the actual IL generated by the compiler. Furthermore, the IL itself doesn't always faithfully describe the machine code that actually gets executed.

Compilers frequently generate large amounts of code as part of their functionality, and also remove unnecessary code as an optimization. Whole loops and method calls may be removed in some cases.

This means that sometimes, the code that is benchmarked isn't the code you actually wrote.

**Funq** handles this using the only way it can be handled: familiarity with the compilers in question, and direct examination of the generated IL.

However, **Funq** is especially susceptible to this, since many of the features it uses to solve the other problems involve large amounts IL-level code generation, provided by the F# compiler (using the feature known as `inline` functions).